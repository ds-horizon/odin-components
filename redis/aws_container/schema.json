{
  "title": "Redis AWS Container (EKS) Flavour Configuration",
  "type": "object",
  "allOf": [
    {
      "if": {
        "properties": {
          "deploymentMode": { "const": "cluster" }
        }
      },
      "then": {
        "required": ["cluster"],
        "errorMessage": "deploymentMode 'cluster' requires cluster configuration with numShards and replicasPerShard"
      }
    },
    {
      "if": {
        "properties": {
          "deploymentMode": { "const": "sentinel" }
        }
      },
      "then": {
        "properties": {
          "sentinel": {
            "properties": {
              "enabled": { "const": true }
            }
          },
          "replica": {
            "properties": {
              "count": { "minimum": 1 }
            }
          }
        },
        "errorMessage": "deploymentMode 'sentinel' requires sentinel.enabled: true and at least 1 replica (replica.count >= 1)"
      }
    },
    {
      "if": {
        "properties": {
          "sentinel": {
            "properties": {
              "enabled": { "const": true }
            }
          }
        }
      },
      "then": {
        "properties": {
          "replica": {
            "properties": {
              "count": { "minimum": 1 }
            }
          }
        },
        "errorMessage": "Sentinel requires at least 1 replica (replica.count >= 1)"
      }
    },
    {
      "if": {
        "properties": {
          "deploymentMode": { "const": "cluster" }
        }
      },
      "then": {
        "not": {
          "required": ["replica"]
        },
        "errorMessage": "deploymentMode 'cluster' should not define 'replica' configuration - use 'cluster.replicasPerShard' instead"
      }
    },
    {
      "if": {
        "properties": {
          "backup": {
            "properties": {
              "enabled": { "const": true }
            }
          }
        }
      },
      "then": {
        "properties": {
          "backup": {
            "required": ["s3Bucket"]
          }
        },
        "errorMessage": "backup.enabled requires backup.s3Bucket to be specified"
      }
    },
    {
      "if": {
        "properties": {
          "cluster": {
            "properties": {
              "numShards": { "minimum": 2 }
            }
          }
        }
      },
      "then": {
        "properties": {
          "deploymentMode": { "const": "cluster" }
        },
        "errorMessage": "Multiple shards (numShards >= 2) requires deploymentMode: 'cluster'"
      }
    },
    {
      "if": {
        "properties": {
          "deploymentMode": { "const": "cluster" }
        }
      },
      "then": {
        "properties": {
          "clusterModeEnabled": { "const": true }
        },
        "errorMessage": "deploymentMode: 'cluster' requires clusterModeEnabled: true in root schema"
      }
    },
    {
      "if": {
        "properties": {
          "clusterModeEnabled": { "const": false }
        }
      },
      "then": {
        "properties": {
          "deploymentMode": {
            "enum": ["standalone", "sentinel"]
          }
        },
        "errorMessage": "clusterModeEnabled: false does not support deploymentMode: 'cluster' - use 'standalone' or 'sentinel'"
      }
    }
  ],
  "properties": {
    "namespace": {
      "type": "string",
      "pattern": "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$",
      "maxLength": 63,
      "description": "Kubernetes namespace where Redis will be deployed. Namespace must follow Kubernetes naming conventions (lowercase alphanumeric and hyphens). If the namespace doesn't exist, it should be created before deployment. **Default: `redis`**.",
      "default": "redis"
    },
    "deploymentMode": {
      "type": "string",
      "enum": ["standalone", "sentinel", "cluster"],
      "description": "Redis deployment topology determining high availability and scaling characteristics. **Standalone:** Single Redis instance with no automatic failover - simplest and most cost-effective for development, testing, and non-critical workloads. **Sentinel:** Master-replica topology with Sentinel processes for automatic failover (recommended for production HA). **Cluster:** Horizontal scaling with data sharding across multiple master nodes, each with replicas. Cluster mode requires `clusterModeEnabled: true` in root schema. **Default: `standalone`** (simplest, lowest cost for getting started). **Production:** Use sentinel for HA with single dataset, cluster for horizontal scaling needs. **IMPORTANT:** Changing deployment mode requires application code changes - see deployment modes documentation.",
      "default": "standalone"
    },
    "master": {
      "type": "object",
      "description": "Resource allocation and configuration for Redis master node(s). The master handles all write operations and serves as the source of truth for data replication.",
      "properties": {
        "resources": {
          "type": "object",
          "description": "Kubernetes resource requests and limits for master pods. Requests guarantee minimum resources; limits cap maximum usage. Setting requests equal to limits provides Guaranteed QoS (recommended for production). Memory should account for dataset size plus 30% overhead for Redis operations, replication buffers, and persistence.",
          "properties": {
            "requests": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Minimum CPU guaranteed for master. Redis is primarily single-threaded (50K ops/sec per core for simple commands). Format: millicores (e.g., '500m') or cores (e.g., '1'). **Default: `500m`** (0.5 cores, suitable for moderate workloads). **Production:** Start with 500m-1000m, monitor CPU usage, adjust based on command latency.",
                  "default": "500m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Minimum memory guaranteed for master. Should be dataset size × 1.3 to account for Redis overhead (replication buffers, persistence, fragmentation). Format: Mi or Gi (e.g., '1Gi', '512Mi'). **Default: `1Gi`** (suitable for ~700MB dataset). **Production:** Calculate as (expected dataset size × 1.3), monitor memory usage and fragmentation ratio.",
                  "default": "1Gi"
                }
              },
              "required": ["cpu", "memory"]
            },
            "limits": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Maximum CPU the master can use. Can be higher than requests to allow bursting. For Guaranteed QoS (production), set equal to requests. **Default: `1000m`** (1 core, 2x burst capacity). **Production:** Set equal to requests for predictable performance.",
                  "default": "1000m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Maximum memory the master can use. Exceeding this triggers OOMKilled. Memory limits should be close to requests to prevent excessive swapping. **Default: `2Gi`** (2x burst capacity). **Production:** Set equal to requests for Guaranteed QoS and predictable memory allocation.",
                  "default": "2Gi"
                }
              },
              "required": ["cpu", "memory"]
            }
          },
          "required": ["requests", "limits"]
        }
      },
      "required": ["resources"]
    },
    "replica": {
      "type": "object",
      "description": "Replica configuration for standalone or sentinel mode. Replicas serve read operations and provide failover redundancy. In sentinel mode, replicas enable automatic failover when master fails. **IMPORTANT:** This configuration is only valid for `deploymentMode: standalone` or `deploymentMode: sentinel`. For `deploymentMode: cluster`, use `cluster.replicasPerShard` instead. Configuration validation should enforce this constraint.",
      "properties": {
        "count": {
          "type": "number",
          "minimum": 0,
          "maximum": 5,
          "description": "Number of read replicas for the Redis master. Replicas provide high availability through automatic failover (when using sentinel mode) and read scaling. Each replica maintains a full copy of the data. Valid range: 0-5 (limited by Opstree operator). Set to 0 for development and standalone mode (no HA). **Default: `0`** (no replicas for simplest setup). **Production:** Use 1-2 replicas with sentinel mode for HA; 3+ for read-heavy workloads. **Note:** Replicas without sentinel mode provide read scaling but NOT automatic failover.",
          "default": 0
        },
        "resources": {
          "type": "object",
          "description": "Kubernetes resource requests and limits for replica pods. Typically same as master since replicas maintain full data copies and may be promoted to master. Can be lower if replicas only serve reads and promotion latency is acceptable.",
          "properties": {
            "requests": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Minimum CPU guaranteed for replicas. **Default: `500m`** (same as master for consistent performance). **Production:** Match master resources if replicas handle production read traffic.",
                  "default": "500m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Minimum memory guaranteed for replicas. Must hold full dataset copy. **Default: `1Gi`** (same as master). **Production:** Match master memory allocation.",
                  "default": "1Gi"
                }
              },
              "required": ["cpu", "memory"]
            },
            "limits": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Maximum CPU for replicas. **Default: `1000m`** (same as master). **Production:** Match master for consistent failover behavior.",
                  "default": "1000m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Maximum memory for replicas. **Default: `2Gi`** (same as master). **Production:** Match master memory limits.",
                  "default": "2Gi"
                }
              },
              "required": ["cpu", "memory"]
            }
          },
          "required": ["requests", "limits"]
        }
      },
      "required": ["count", "resources"]
    },
    "persistence": {
      "type": "object",
      "description": "Persistent storage configuration using Kubernetes PersistentVolumeClaims (PVCs). Enables data durability across pod restarts. Uses EBS volumes in EKS, which are AZ-specific (pods must be in same AZ as their volumes).",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable persistent storage for Redis data. When true, creates PVCs for each Redis pod to store RDB/AOF files. When false, uses emptyDir (data lost on pod deletion). **Default: `true`** (data durability). **Production:** Always enable for any production data.",
          "default": true
        },
        "storageClass": {
          "type": "string",
          "description": "Kubernetes StorageClass name determining the EBS volume type and provisioning behavior. StorageClass must exist in the cluster and should use `volumeBindingMode: WaitForFirstConsumer` for topology-aware provisioning (ensures pod and volume are in same AZ). **Default: `gp3`** (AWS EBS gp3 volumes: 3000 IOPS, 125MB/s baseline, $0.08/GB-month). **Production:** Use gp3-encrypted (or create encrypted StorageClass with `encrypted: true` parameter) for data encryption at rest; io2 only for extreme IOPS needs. **Security:** For at-rest encryption, create StorageClass with `parameters.encrypted: 'true'` and optional `parameters.kmsKeyId` for customer-managed keys (required for HIPAA, PCI-DSS compliance). EBS encryption is free and transparent to Redis with zero performance impact.",
          "default": "gp3"
        },
        "size": {
          "type": "string",
          "pattern": "^[0-9]+(Mi|Gi|Ti)$",
          "description": "Size of persistent volume per Redis pod. Should be at least 2-3x expected dataset size to account for RDB snapshots, AOF files, and growth. Format: Mi, Gi, or Ti (e.g., '10Gi', '100Gi'). Supports volume expansion if StorageClass has `allowVolumeExpansion: true`. **Default: `10Gi`** (suitable for small datasets). **Production:** Calculate as (expected dataset size × 2.5) for RDB forks and AOF rewrites, plus growth buffer.",
          "default": "10Gi"
        },
        "rdb": {
          "type": "object",
          "description": "Redis Database (RDB) snapshot configuration for point-in-time backups. RDB creates binary snapshots of the dataset at specified intervals. Faster to load than AOF but may lose data between snapshots.",
          "properties": {
            "enabled": {
              "type": "boolean",
              "description": "Enable RDB snapshots. When true, Redis periodically saves snapshots to disk based on save intervals. Provides faster restart times compared to AOF. **Default: `true`** (recommended for most use cases). **Production:** Enable for faster recovery; combine with AOF for maximum durability.",
              "default": true
            },
            "saveInterval": {
              "type": "string",
              "pattern": "^(\\d+\\s+\\d+(\\s+\\d+\\s+\\d+)*)$|^\"\"$",
              "description": "RDB snapshot save intervals in Redis format: `<seconds> <changes> [<seconds> <changes> ...]`. Redis saves a snapshot if at least `<changes>` keys changed in `<seconds>` seconds. Multiple intervals can be specified (space-separated). Set to empty string `\"\"` to disable RDB. **Default: `\"900 1 300 10 60 10000\"`** (Redis defaults: save after 900s if 1+ keys changed, after 300s if 10+ keys changed, after 60s if 10000+ keys changed). **Production:** Adjust based on write frequency and acceptable data loss window; more frequent saves increase I/O but reduce data loss.",
              "default": "900 1 300 10 60 10000"
            }
          }
        },
        "aof": {
          "type": "object",
          "description": "Append-Only File (AOF) configuration for durable write logging. AOF logs every write operation, providing better durability than RDB. Slower to load on restart but minimal data loss (typically <1 second).",
          "properties": {
            "enabled": {
              "type": "boolean",
              "description": "Enable AOF persistence. When true, Redis logs every write to an append-only file on disk. Provides maximum durability based on fsyncPolicy setting. Increases disk I/O and storage usage. **Default: `false`** (RDB only for dev/test simplicity). **Production:** Enable for critical data where data loss is unacceptable; disable for caching workloads where data can be regenerated.",
              "default": false
            },
            "fsyncPolicy": {
              "type": "string",
              "enum": ["always", "everysec", "no"],
              "description": "AOF fsync policy controlling when Redis forces writes to disk. **always:** fsync after every write (safest, slowest - ensures zero data loss but high I/O overhead). **everysec:** fsync every second in background thread (recommended balance - at most 1 second of data loss, minimal performance impact). **no:** never fsync, let OS decide (fastest, riskiest - potential minutes of data loss on system crash). **Default: `everysec`** (Redis recommendation - good balance of safety and performance). **Production:** Use everysec for most workloads; always only for critical financial/transactional data where zero data loss is required; never use no in production.",
              "default": "everysec"
            }
          }
        }
      },
      "required": ["enabled"]
    },
    "sentinel": {
      "type": "object",
      "description": "Redis Sentinel configuration for high availability and automatic failover in sentinel deployment mode. Sentinel monitors master and replicas, performing automatic promotion when master fails. Requires at least 3 sentinel processes (odd number) for quorum.",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable Redis Sentinel for automatic failover. When true, deploys separate Sentinel processes to monitor Redis master and replicas. Required when `deploymentMode: sentinel`. Provides automatic master promotion on failure (typically 15-30 second failover time). **Default: `false`** (disabled for standalone mode by default). **Production:** Set to true when using `deploymentMode: sentinel` for automatic failover.",
          "default": false
        },
        "replicas": {
          "type": "number",
          "enum": [3, 5, 7],
          "description": "Number of Sentinel processes. Must be odd number (3, 5, 7) for proper quorum and split-brain prevention. Sentinels vote on failover decisions; quorum determines minimum agreeing sentinels for promotion. More sentinels increase availability but add resource overhead. **Default: `3`** (minimum recommended for production HA). **Production:** 3 sentinels sufficient for most cases; 5 for critical workloads spanning multiple AZs.",
          "default": 3
        },
        "quorum": {
          "type": "number",
          "minimum": 2,
          "description": "Minimum number of Sentinels that must agree master is down before initiating failover. Should be majority of sentinels (e.g., 2 for 3 sentinels, 3 for 5 sentinels). Lower values enable faster failover but increase risk of false positives; higher values are more conservative. **Default: `2`** (majority for 3 sentinels). **Production:** Set to (sentinels / 2) + 1 for proper majority.",
          "default": 2
        },
        "resources": {
          "type": "object",
          "description": "Kubernetes resource allocation for Sentinel processes. Sentinels are lightweight (primarily network I/O and health checks), requiring minimal resources compared to Redis nodes.",
          "properties": {
            "requests": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Minimum CPU for Sentinel processes. **Default: `100m`** (0.1 cores, sufficient for monitoring). **Production:** 100m adequate for most deployments.",
                  "default": "100m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Minimum memory for Sentinel processes. **Default: `128Mi`** (sufficient for Sentinel state). **Production:** 128Mi adequate for typical deployments.",
                  "default": "128Mi"
                }
              },
              "required": ["cpu", "memory"]
            },
            "limits": {
              "type": "object",
              "properties": {
                "cpu": {
                  "type": "string",
                  "pattern": "^[0-9]+(m|\\.[0-9]+)?$",
                  "description": "Maximum CPU for Sentinel processes. **Default: `200m`** (2x burst capacity). **Production:** 200m provides adequate headroom.",
                  "default": "200m"
                },
                "memory": {
                  "type": "string",
                  "pattern": "^[0-9]+(Mi|Gi)$",
                  "description": "Maximum memory for Sentinel processes. **Default: `256Mi`** (2x base allocation). **Production:** 256Mi adequate with headroom.",
                  "default": "256Mi"
                }
              },
              "required": ["cpu", "memory"]
            }
          },
          "required": ["requests", "limits"]
        }
      }
    },
    "cluster": {
      "type": "object",
      "description": "Redis Cluster mode configuration for horizontal scaling through data sharding. **IMPORTANT:** This configuration is only valid when BOTH conditions are met: (1) `clusterModeEnabled: true` in root schema AND (2) `deploymentMode: cluster` in this flavour schema. This cross-schema dependency must be validated at the configuration composition layer. Distributes 16,384 hash slots across multiple master nodes for write scaling and larger datasets.",
      "properties": {
        "numShards": {
          "type": "number",
          "minimum": 3,
          "maximum": 500,
          "description": "Number of shards (master nodes) in the Redis Cluster. Each shard handles a portion of the 16,384 hash slots. More shards increase write throughput and total capacity but add operational complexity. Minimum 3 required for proper cluster operation. **Default: `3`** (minimum recommended for cluster mode). **Production:** Start with 3-6 shards for most use cases; scale based on write throughput needs (add shards for write scaling, add replicas for read scaling).",
          "default": 3
        },
        "replicasPerShard": {
          "type": "number",
          "minimum": 1,
          "maximum": 5,
          "description": "Number of replicas per shard in cluster mode. Each shard (master) gets this many replicas for HA and read scaling. Total pods = numShards × (1 + replicasPerShard). Valid range: 1-5. Higher values increase availability and read throughput but multiply costs. **Default: `1`** (each shard has 1 replica for basic HA). **Production:** Use 1-2 replicas per shard; 2 for critical workloads with multi-AZ distribution.",
          "default": 1
        }
      },
      "required": ["numShards", "replicasPerShard"]
    },
    "antiAffinity": {
      "type": "string",
      "enum": ["soft", "required"],
      "description": "Pod anti-affinity strategy controlling how Redis pods are distributed across Kubernetes nodes. Prevents multiple Redis pods (masters or replicas) from running on the same node for better availability during node failures. **Soft (preferredDuringScheduling):** Scheduler prefers spreading pods but will co-locate if necessary (e.g., insufficient nodes). **Required (requiredDuringScheduling):** Scheduler strictly enforces spreading, pods won't schedule if it violates anti-affinity. **Default: `soft`** (distribute when possible, don't block deployment). **Production:** Use required for strict HA guarantees in clusters with 3+ nodes; soft for smaller clusters or development.",
      "default": "soft"
    },
    "topologySpreadConstraints": {
      "type": "array",
      "description": "Kubernetes topology spread constraints for distributing Redis pods across availability zones (AZs) and nodes. Enables multi-AZ high availability by ensuring pods are spread across different failure domains. Use this for production to survive AZ outages.",
      "items": {
        "type": "object",
        "properties": {
          "maxSkew": {
            "type": "number",
            "minimum": 1,
            "description": "Maximum difference in pod count between any two topology domains (e.g., AZs). For example, maxSkew: 1 means if one AZ has 2 pods, another can have at most 3 (1 more). Lower values enforce tighter distribution. **Production:** Use 1 for even distribution across AZs.",
            "default": 1
          },
          "topologyKey": {
            "type": "string",
            "description": "Node label key defining the topology domain. Common values: `topology.kubernetes.io/zone` (spread across AZs), `kubernetes.io/hostname` (spread across nodes). **Production:** Use zone for multi-AZ HA.",
            "examples": ["topology.kubernetes.io/zone", "kubernetes.io/hostname"]
          },
          "whenUnsatisfiable": {
            "type": "string",
            "enum": ["DoNotSchedule", "ScheduleAnyway"],
            "description": "Action when spread constraint cannot be satisfied. **DoNotSchedule:** Pod remains pending if constraint can't be met (strict enforcement). **ScheduleAnyway:** Pod scheduled anyway, violating constraint (soft enforcement). **Production:** Use DoNotSchedule for AZ spreading to guarantee multi-AZ deployment."
          }
        },
        "required": ["maxSkew", "topologyKey", "whenUnsatisfiable"]
      },
      "default": []
    },
    "metrics": {
      "type": "object",
      "description": "Prometheus metrics configuration using redis-exporter sidecar. Enables monitoring of Redis performance, memory usage, command statistics, replication lag, and cluster health. Essential for production observability.",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable Prometheus metrics collection via redis-exporter sidecar container. When true, adds redis-exporter (port 9121) to each Redis pod exposing 100+ metrics. Minimal performance impact (<1% CPU/memory overhead). **Default: `false`** (disabled for simplest setup). **Production:** Enable for monitoring and alerting - essential for production observability.",
          "default": false
        },
        "serviceMonitor": {
          "type": "object",
          "description": "Prometheus Operator ServiceMonitor configuration for automatic scrape target discovery. Only applicable if Prometheus Operator is installed in the cluster.",
          "properties": {
            "enabled": {
              "type": "boolean",
              "description": "Create ServiceMonitor custom resource for Prometheus Operator. When true, Prometheus automatically discovers and scrapes Redis metrics. Requires Prometheus Operator CRDs installed. **Default: `false`** (manual Prometheus configuration). **Production:** Enable if using Prometheus Operator for centralized monitoring.",
              "default": false
            },
            "interval": {
              "type": "string",
              "pattern": "^[0-9]+(s|m|h)$",
              "description": "Prometheus scrape interval for collecting metrics. Lower intervals provide finer granularity but increase Prometheus load and storage. Format: seconds (s), minutes (m), or hours (h) (e.g., '30s', '1m'). **Default: `30s`** (good balance of granularity and overhead). **Production:** 15-30s for critical systems, 1m for general monitoring.",
              "default": "30s"
            },
            "namespace": {
              "type": "string",
              "pattern": "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$",
              "description": "Namespace where ServiceMonitor will be created. Typically the monitoring/observability namespace where Prometheus Operator is deployed. Must match Prometheus Operator's serviceMonitorNamespaceSelector. **Default: `monitoring`**.",
              "default": "monitoring"
            }
          }
        }
      }
    },
    "backup": {
      "type": "object",
      "description": "Automated backup configuration for Redis data to AWS S3. Creates scheduled backups of RDB snapshots for disaster recovery. Backups are critical for production to enable point-in-time recovery from data corruption, accidental deletion, or AZ failures.",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable automated backups to S3. When true, creates a Kubernetes CronJob that periodically triggers Redis SAVE, copies RDB files, and uploads to S3. Requires S3 bucket and IAM permissions (EKS IRSA recommended). **Default: `false`** (optional feature, adds complexity). **Production:** Enable for any critical data; implement 3-2-1 backup strategy (3 copies, 2 media, 1 offsite).",
          "default": false
        },
        "schedule": {
          "type": "string",
          "pattern": "^(@(annually|yearly|monthly|weekly|daily|hourly|reboot))|(@every (\\d+(ns|us|µs|ms|s|m|h))+)|((((\\d+,)+\\d+|(\\d+([/\\-])\\d+)|\\d+|\\*) ?){5,7})$",
          "description": "Cron schedule for automated backups in standard cron format or special strings. Format: `minute hour day month weekday` (e.g., `0 2 * * *` for 2 AM daily). Special strings: `@daily`, `@weekly`, `@monthly`. Schedule during low-traffic periods to minimize performance impact. **Default: `0 2 * * *`** (2 AM UTC daily). **Production:** Daily backups at 2-4 AM; hourly for mission-critical data.",
          "default": "0 2 * * *"
        },
        "s3Bucket": {
          "type": "string",
          "pattern": "^[a-z0-9][a-z0-9\\-]*[a-z0-9]$",
          "description": "AWS S3 bucket name for storing Redis backups. Bucket must exist with versioning enabled (recommended) and lifecycle policies for retention management. IAM role (via IRSA) must have s3:PutObject permission. Use cross-region replication for disaster recovery. **Production:** Dedicated backup bucket with versioning, MFA delete, and cross-region replication; implement S3 lifecycle to transition old backups to Glacier for cost savings."
        },
        "s3Region": {
          "type": "string",
          "pattern": "^[a-z]{2}-[a-z]+-\\d$",
          "description": "AWS region where S3 bucket is located. Should match EKS cluster region for lower latency and data transfer costs. For disaster recovery, use cross-region replication to a different region. **Default: `us-east-1`**.",
          "default": "us-east-1"
        },
        "retention": {
          "type": "number",
          "minimum": 1,
          "maximum": 365,
          "description": "Number of days to retain backups before deletion. Implement tiered retention: daily (7 days), weekly (4 weeks), monthly (12 months) using S3 lifecycle policies. Balance between recovery flexibility and storage costs. **Default: `7`** (7 days for development). **Production:** 30 days minimum; 90-365 days for compliance; implement S3 lifecycle for cost optimization (transition to Glacier after 30 days).",
          "default": 7
        }
      }
    },
    "service": {
      "type": "object",
      "description": "Kubernetes Service configuration controlling how Redis is exposed for client connectivity. Defines service type (internal cluster access vs external load balancer) and AWS-specific annotations for load balancer behavior.",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["ClusterIP", "LoadBalancer", "NodePort"],
          "description": "Kubernetes Service type determining Redis accessibility. **ClusterIP:** Internal cluster access only via cluster DNS (redis-master.<namespace>.svc.cluster.local). **LoadBalancer:** Creates AWS NLB for external access (cross-VPC, on-premises). **NodePort:** Exposes on each node's IP at static port (rarely used). **Default: `ClusterIP`** (internal access, security best practice). **Production:** Use ClusterIP for apps in same cluster; LoadBalancer only if external access required (e.g., cross-VPC); always use internal NLB annotation for security.",
          "default": "ClusterIP"
        },
        "annotations": {
          "type": "object",
          "description": "Kubernetes Service annotations for AWS Load Balancer Controller configuration. Key annotations: `service.beta.kubernetes.io/aws-load-balancer-type: nlb` (Network Load Balancer), `service.beta.kubernetes.io/aws-load-balancer-internal: true` (internal NLB), `service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: true` (multi-AZ). **Default: `{}`** (no annotations). **Production:** For LoadBalancer type, always use internal NLB with cross-zone load balancing.",
          "additionalProperties": {
            "type": "string"
          },
          "default": {}
        }
      }
    },
    "networkPolicy": {
      "type": "object",
      "description": "Kubernetes NetworkPolicy for restricting network access to Redis pods using firewall rules at the pod level. Enables zero-trust security by allowing only specified namespaces/pods to connect on port 6379. Requires a CNI plugin that supports NetworkPolicy (Calico, Cilium, AWS VPC CNI with network policy support).",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable NetworkPolicy for Redis. When true, creates policies allowing only specified namespaces to connect on port 6379; denies all other ingress by default. Provides defense-in-depth beyond security groups. Requires CNI with NetworkPolicy support. **Default: `false`** (avoid breaking existing setups). **Production:** Enable for zero-trust security; specify allowed namespaces explicitly.",
          "default": false
        },
        "allowedNamespaces": {
          "type": "array",
          "description": "List of Kubernetes namespace names allowed to access Redis. Namespaces must have matching label for selector (e.g., `name: <namespace>`). Empty array denies all external access (only same-namespace). **Production:** Explicitly list application namespaces requiring Redis access; never use `*` (all namespaces).",
          "items": {
            "type": "string",
            "pattern": "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$"
          },
          "default": []
        }
      }
    },
    "updateStrategy": {
      "type": "object",
      "description": "Kubernetes StatefulSet update strategy controlling how Redis pods are updated during version upgrades or configuration changes. Determines update order and parallelism to minimize downtime.",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["RollingUpdate", "OnDelete"],
          "description": "Update strategy type. **RollingUpdate:** Automatically updates pods in reverse ordinal order (replicas before master in StatefulSets). Opstree operator manages graceful updates. **OnDelete:** Pods updated only when manually deleted. **Default: `RollingUpdate`** (automated updates). **Production:** Always use RollingUpdate for safe automated deployments.",
          "default": "RollingUpdate"
        },
        "rollingUpdate": {
          "type": "object",
          "properties": {
            "maxUnavailable": {
              "type": "number",
              "minimum": 0,
              "description": "Maximum number of pods unavailable during update. For StatefulSets, typically 1 (update one pod at a time). Combined with PodDisruptionBudget ensures availability during updates. **Default: `1`** (one pod at a time). **Production:** Keep at 1 to maintain quorum/availability during updates.",
              "default": 1
            }
          }
        }
      }
    },
    "podDisruptionBudget": {
      "type": "object",
      "description": "Kubernetes PodDisruptionBudget (PDB) controlling availability during voluntary disruptions (node drains, cluster upgrades, operator updates). Ensures minimum pods remain available during maintenance, preventing service outages.",
      "properties": {
        "enabled": {
          "type": "boolean",
          "description": "Enable PodDisruptionBudget for Redis pods. When true, Kubernetes prevents voluntary disruptions (node drains) if they would violate minAvailable. Protects against simultaneous pod evictions. **Default: `true`** (availability protection). **Production:** Always enable to prevent outages during cluster maintenance.",
          "default": true
        },
        "minAvailable": {
          "type": "number",
          "minimum": 1,
          "description": "Minimum number of Redis pods that must remain available during disruptions. For sentinel: typically 2 (1 master + 1 replica). For cluster: ensure quorum (majority of masters available). Prevents multiple simultaneous evictions. **Default: `1`** (at least 1 pod always available). **Production:** Sentinel: set to 2; Cluster (6 nodes): set to 4 (majority of 6).",
          "default": 1
        }
      }
    },
    "serviceAccount": {
      "type": "string",
      "pattern": "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$",
      "description": "Kubernetes ServiceAccount name for Redis pods. ServiceAccount provides pod identity for RBAC and IAM roles (via IRSA). Use for S3 backups, Secrets Manager integration, or CloudWatch access. Create ServiceAccount with appropriate IAM role annotation before deployment. **Default: `default`** (namespace default SA). **Production:** Create dedicated ServiceAccount with minimal IAM permissions (principle of least privilege); annotate with IAM role ARN for IRSA.",
      "default": "default"
    },
    "nodeSelector": {
      "type": "object",
      "description": "Kubernetes node selector for constraining Redis pods to specific nodes based on labels. Use for dedicated Redis node pools, instance type selection (memory-optimized r5 instances), or cost optimization (spot vs on-demand). Format: key-value pairs matching node labels. **Production:** Use for dedicating memory-optimized nodes to Redis; separate master (on-demand) from replicas (spot).",
      "additionalProperties": {
        "type": "string"
      },
      "default": {}
    },
    "tolerations": {
      "type": "array",
      "description": "Kubernetes tolerations allowing Redis pods to schedule on tainted nodes. Use with taints to dedicate nodes for Redis or enable spot instance replicas. Each toleration matches a taint to override scheduling restriction.",
      "items": {
        "type": "object",
        "properties": {
          "key": {
            "type": "string",
            "description": "Taint key to tolerate (e.g., 'redis', 'spot')."
          },
          "operator": {
            "type": "string",
            "enum": ["Equal", "Exists"],
            "description": "Comparison operator. Equal: key/value must match. Exists: only key must match."
          },
          "value": {
            "type": "string",
            "description": "Taint value to match (when operator: Equal)."
          },
          "effect": {
            "type": "string",
            "enum": ["NoSchedule", "PreferNoSchedule", "NoExecute"],
            "description": "Taint effect. NoSchedule: block scheduling. NoExecute: evict existing pods."
          }
        }
      },
      "default": []
    },
    "priorityClassName": {
      "type": "string",
      "description": "Kubernetes PriorityClass name determining pod scheduling priority during resource contention. Higher priority pods preempt lower priority pods when cluster resources are scarce. Create PriorityClass before referencing. **Production:** Use high priority for production Redis to prevent eviction by batch jobs; create PriorityClass with value 1000+ for critical workloads.",
      "default": ""
    },
    "securityContext": {
      "type": "object",
      "description": "Kubernetes pod-level security context for Redis pods. Defines user/group IDs, filesystem permissions, and security constraints following pod security standards. Opstree operator typically manages this, but can be overridden for compliance.",
      "properties": {
        "runAsNonRoot": {
          "type": "boolean",
          "description": "Require Redis to run as non-root user. **Default: `true`** (security best practice). **Production:** Always enable to reduce attack surface.",
          "default": true
        },
        "runAsUser": {
          "type": "number",
          "description": "User ID to run Redis process. Opstree default: 1000. Must have write access to /data volume. **Default: `1000`**.",
          "default": 1000
        },
        "fsGroup": {
          "type": "number",
          "description": "Group ID for volume ownership. Ensures PVC volumes are writable by Redis process. **Default: `1000`**.",
          "default": 1000
        }
      }
    },
    "additionalConfig": {
      "type": "object",
      "description": "Additional Redis configuration parameters to override defaults. Supports any redis.conf setting as key-value pairs. Common parameters: maxmemory-policy (eviction), tcp-keepalive, timeout, client-output-buffer-limit. Use for advanced tuning; most settings have sensible operator defaults. **Production:** Override maxmemory-policy for caching (allkeys-lru) vs persistence (noeviction); tune client-output-buffer-limit for pub/sub workloads.",
      "additionalProperties": {
        "type": "string"
      },
      "default": {}
    }
  },
  "required": []
}
